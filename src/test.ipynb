{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "#import config\n",
    "import pandas as pd\n",
    "#from io import StringIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "athena_client = boto3.client(\n",
    "    \"athena\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_KEY,\n",
    "    region_name=AWS_REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_response = athena_client.start_query_execution(\n",
    "    QueryString=\"SELECT * FROM enigma_jhu_enigma_jhu\",\n",
    "    QueryExecutionContext={\"Database\": SCHEMA_NAME},\n",
    "    ResultConfiguration={\n",
    "        \"OutputLocation\": S3_STAGING_DIR,\n",
    "        #\"EncryptionConfiguration\": {\"EncryptionOption\": \"SSE_S3\"},\n",
    "    },\n",
    ")\n",
    "while True:\n",
    "    try:\n",
    "        # This function only loads the first 1000 rows\n",
    "        athena_client.get_query_results(\n",
    "            QueryExecutionId=query_response[\"QueryExecutionId\"]\n",
    "        )\n",
    "        break\n",
    "    except Exception as err:\n",
    "        if \"not yet finished\" in str(err):\n",
    "            time.sleep(0.001)\n",
    "        else:\n",
    "            raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_file_location: str = \"athena_query_results.csv\"\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_KEY,\n",
    "    region_name=AWS_REGION,\n",
    ")\n",
    "s3_client.download_file(\n",
    "    S3_BUCKET_NAME,\n",
    "    f\"{S3_OUTPUT_DIRECTORY}/{query_response['QueryExecutionId']}.csv\",\n",
    "    temp_file_location,\n",
    ")\n",
    "df = pd.read_csv(temp_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>admin2</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>last_update</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>combined_key</th>\n",
       "      <th>partition_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22T17:00:00</td>\n",
       "      <td>31.826</td>\n",
       "      <td>117.226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Anhui</td>\n",
       "      <td>csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22T17:00:00</td>\n",
       "      <td>40.182</td>\n",
       "      <td>116.414</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Beijing</td>\n",
       "      <td>csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22T17:00:00</td>\n",
       "      <td>30.057</td>\n",
       "      <td>107.874</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Chongqing</td>\n",
       "      <td>csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22T17:00:00</td>\n",
       "      <td>26.079</td>\n",
       "      <td>117.987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Fujian</td>\n",
       "      <td>csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>China</td>\n",
       "      <td>2020-01-22T17:00:00</td>\n",
       "      <td>36.061</td>\n",
       "      <td>103.834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Gansu</td>\n",
       "      <td>csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips admin2 province_state country_region          last_update  latitude  \\\n",
       "0   NaN    NaN          Anhui          China  2020-01-22T17:00:00    31.826   \n",
       "1   NaN    NaN        Beijing          China  2020-01-22T17:00:00    40.182   \n",
       "2   NaN    NaN      Chongqing          China  2020-01-22T17:00:00    30.057   \n",
       "3   NaN    NaN         Fujian          China  2020-01-22T17:00:00    26.079   \n",
       "4   NaN    NaN          Gansu          China  2020-01-22T17:00:00    36.061   \n",
       "\n",
       "   longitude  confirmed  deaths  recovered  active combined_key partition_0  \n",
       "0    117.226        1.0     NaN        NaN     NaN       \"Anhui         csv  \n",
       "1    116.414       14.0     NaN        NaN     NaN     \"Beijing         csv  \n",
       "2    107.874        6.0     NaN        NaN     NaN   \"Chongqing         csv  \n",
       "3    117.987        1.0     NaN        NaN     NaN      \"Fujian         csv  \n",
       "4    103.834        NaN     NaN        NaN     NaN       \"Gansu         csv  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
